{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0UJUQTblGeFLdRQKg/WGt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loveberryc/SpikeNet/blob/master/SpikeNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbf431mhZTKQ",
        "outputId": "56250200-2815-4f1e-fc78-11a028a86016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SpikeNet'...\n",
            "remote: Enumerating objects: 624, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 624 (delta 15), reused 0 (delta 0), pack-reused 600\u001b[K\n",
            "Receiving objects: 100% (624/624), 1.17 MiB | 7.95 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "/content/SpikeNet\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting charset-normalizer==2.1.0\n",
            "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (0.11.0)\n",
            "Collecting fonttools==4.33.3\n",
            "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.9/930.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==3.3\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver==1.4.3\n",
            "  Downloading kiwisolver-1.4.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib==3.5.2\n",
            "  Downloading matplotlib-3.5.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.6\n",
            "  Downloading numpy-1.21.6-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==21.3\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.3.5\n",
            "  Downloading pandas-1.3.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0\n",
            "  Downloading Pillow-9.2.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (2.8.2)\n",
            "Collecting pytz==2022.1\n",
            "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.28.1\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.16.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 15)) (1.16.0)\n",
            "Collecting snntorch==0.5.1\n",
            "  Downloading snntorch-0.5.1-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.12.0\n",
            "  Downloading torch-1.12.0-cp39-cp39-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.13.0\n",
            "  Downloading torchvision-0.13.0-cp39-cp39-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.0\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==4.3.0\n",
            "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
            "Collecting urllib3==1.26.9\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests==2.28.1->-r requirements.txt (line 14)) (2022.12.7)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from fvcore->-r requirements.txt (line 22)) (6.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.9/dist-packages (from fvcore->-r requirements.txt (line 22)) (2.2.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from fvcore->-r requirements.txt (line 22)) (0.8.10)\n",
            "Collecting iopath>=0.1.7\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61429 sha256=2b768d6302d9471e3280fff174950b498cb03e73abd66fddac07a3eabc02e8c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/42/02/66178d16e5c44dc26d309931834956baeda371956e86fbd876\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=3b654409fb236eab0d7b8610893e9440bae40787a889170b7aff27f073d17119\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: pytz, yacs, urllib3, typing_extensions, tqdm, portalocker, Pillow, packaging, numpy, kiwisolver, idna, fonttools, charset-normalizer, torch, requests, pandas, matplotlib, iopath, torchvision, snntorch, fvcore\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2022.7.1\n",
            "    Uninstalling pytz-2022.7.1:\n",
            "      Successfully uninstalled pytz-2022.7.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.15\n",
            "    Uninstalling urllib3-1.26.15:\n",
            "      Successfully uninstalled urllib3-1.26.15\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.4\n",
            "    Uninstalling kiwisolver-1.4.4:\n",
            "      Successfully uninstalled kiwisolver-1.4.4\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: fonttools\n",
            "    Found existing installation: fonttools 4.39.3\n",
            "    Uninstalling fonttools-4.39.3:\n",
            "      Successfully uninstalled fonttools-4.39.3\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 2.0.12\n",
            "    Uninstalling charset-normalizer-2.0.12:\n",
            "      Successfully uninstalled charset-normalizer-2.0.12\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.18 requires pytz>=2022.5, but you have pytz 2022.1 which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.2.0 charset-normalizer-2.1.0 fonttools-4.33.3 fvcore-0.1.5.post20221221 idna-3.3 iopath-0.1.10 kiwisolver-1.4.3 matplotlib-3.5.2 numpy-1.21.6 packaging-21.3 pandas-1.3.5 portalocker-2.7.0 pytz-2022.1 requests-2.28.1 snntorch-0.5.1 torch-1.12.0 torchvision-0.13.0 tqdm-4.64.0 typing_extensions-4.3.0 urllib3-1.26.9 yacs-0.1.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-score>=0.3.5\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 2)) (0.6.2)\n",
            "Collecting flair\n",
            "  Downloading flair-0.12.2-py3-none-any.whl (373 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.1/373.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 4)) (3.11.0)\n",
            "Collecting language_tool_python\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Collecting lemminflect\n",
            "  Downloading lemminflect-0.2.3-py3-none-any.whl (769 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.7/769.7 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lru-dict\n",
            "  Downloading lru_dict-1.1.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Collecting datasets==2.4.0\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 9)) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 10)) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 11)) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 12)) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 13)) (1.12.0)\n",
            "Collecting transformers>=4.21.0\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 16)) (4.64.0)\n",
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting num2words\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 19)) (9.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 20)) (1.7.1)\n",
            "Collecting pinyin==0.4.0\n",
            "  Downloading pinyin-0.4.0.tar.gz (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 22)) (0.42.1)\n",
            "Collecting OpenHowNet\n",
            "  Downloading OpenHowNet-2.0-py3-none-any.whl (18 kB)\n",
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting click<8.1.0\n",
            "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.5/97.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from -r textattack_r.txt (line 26)) (2.12.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.4.0->-r textattack_r.txt (line 8)) (2.28.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets==2.4.0->-r textattack_r.txt (line 8)) (9.0.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets==2.4.0->-r textattack_r.txt (line 8)) (2023.4.0)\n",
            "Collecting dill<0.3.6\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets==2.4.0->-r textattack_r.txt (line 8)) (21.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from bert-score>=0.3.5->-r textattack_r.txt (line 1)) (3.5.2)\n",
            "Requirement already satisfied: hyperopt>=0.2.7 in /usr/local/lib/python3.9/dist-packages (from flair->-r textattack_r.txt (line 3)) (0.2.7)\n",
            "Requirement already satisfied: gensim>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from flair->-r textattack_r.txt (line 3)) (4.3.1)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from flair->-r textattack_r.txt (line 3)) (0.8.10)\n",
            "Collecting pytorch-revgrad\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.9/dist-packages (from flair->-r textattack_r.txt (line 3)) (2.8.2)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.9/dist-packages (from flair->-r textattack_r.txt (line 3)) (1.2.2)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.1\n",
            "  Downloading transformer_smaller_training_vocab-0.2.3-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from flair->-r textattack_r.txt (line 3)) (4.9.2)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from flair->-r textattack_r.txt (line 3)) (2022.10.31)\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia_API-0.5.8-py3-none-any.whl (13 kB)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.118-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==4.4.0\n",
            "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown==4.4.0->flair->-r textattack_r.txt (line 3)) (4.11.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown==4.4.0->flair->-r textattack_r.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->-r textattack_r.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0.1->-r textattack_r.txt (line 11)) (2022.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (4.3.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.21.0->-r textattack_r.txt (line 14)) (6.0)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting anytree\n",
            "  Downloading anytree-2.8.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from OpenHowNet->-r textattack_r.txt (line 23)) (67.6.1)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (2.12.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (3.20.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (1.53.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (1.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (2.2.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (0.4.8)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (1.14.1)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (0.32.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (3.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (23.3.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->-r textattack_r.txt (line 26)) (0.2.0)\n",
            "Collecting numpy>=1.21.0\n",
            "  Downloading numpy-1.23.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->-r textattack_r.txt (line 26)) (0.40.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.4.0->-r textattack_r.txt (line 8)) (2.1.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.3/269.3 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets==2.4.0->-r textattack_r.txt (line 8)) (23.1.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim>=3.8.0->flair->-r textattack_r.txt (line 3)) (6.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.7->flair->-r textattack_r.txt (line 3)) (3.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.7->flair->-r textattack_r.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.7->flair->-r textattack_r.txt (line 3)) (0.18.3)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.9/dist-packages (from hyperopt>=0.2.7->flair->-r textattack_r.txt (line 3)) (0.10.9.7)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow->-r textattack_r.txt (line 26)) (0.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score>=0.3.5->-r textattack_r.txt (line 1)) (4.33.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score>=0.3.5->-r textattack_r.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score>=0.3.5->-r textattack_r.txt (line 1)) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score>=0.3.5->-r textattack_r.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->bert-score>=0.3.5->-r textattack_r.txt (line 1)) (9.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r textattack_r.txt (line 8)) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r textattack_r.txt (line 8)) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r textattack_r.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.21.3->flair->-r textattack_r.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (2.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (0.7.0)\n",
            "Collecting transformers[sentencepiece]>=4.18.0\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.27.0-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.23.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]>=4.18.0\n",
            "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.22.0-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.20.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.19.3-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of transformer-smaller-training-vocab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformer-smaller-training-vocab>=0.2.1\n",
            "  Downloading transformer_smaller_training_vocab-0.2.2-py3-none-any.whl (12 kB)\n",
            "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of termcolor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
            "INFO: pip is looking at multiple versions of tensorflow-io-gcs-filesystem to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-estimator to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorboard<2.13,>=2.12\n",
            "  Downloading tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "INFO: pip is looking at multiple versions of sqlitedict to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of six to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "INFO: pip is looking at multiple versions of segtok to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of scikit-learn to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scikit-learn>=0.21.3\n",
            "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of responses to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
            "INFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting requests>=2.19.0\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of regex to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting regex\n",
            "  Downloading regex-2023.3.23-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.0/769.0 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.8/661.8 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of pytz to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pytz>=2017.3\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting python-dateutil>=2.6.1\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of pyarrow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pyarrow>=6.0.0\n",
            "  Downloading pyarrow-11.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
            "  Downloading protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.22.0-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.21.11-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.21.10-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.21.9-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading protobuf-4.21.8-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.21.7-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-4.21.6-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting packaging\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: pip is looking at multiple versions of opt-einsum to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of libclang to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting libclang>=13.0.0\n",
            "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting keras<2.13,>=2.12.0\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15\n",
            "  Downloading jax-0.4.8.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of hyperopt to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of h5py to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.54.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of google-pasta to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of gensim to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gensim>=3.8.0\n",
            "  Downloading gensim-4.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of gast to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "INFO: pip is looking at multiple versions of aiohttp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fsspec[http]>=2021.11.1\n",
            "  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of flatbuffers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
            "INFO: pip is looking at multiple versions of docopt to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dill to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dill<0.3.6\n",
            "  Downloading dill-0.3.5-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of deprecated to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.12-py2.py3-none-any.whl (9.5 kB)\n",
            "INFO: pip is looking at multiple versions of conllu to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.5.1-py2.py3-none-any.whl (16 kB)\n",
            "INFO: pip is looking at multiple versions of bpemb to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "INFO: pip is looking at multiple versions of astunparse to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting numpy>=1.21.0\n",
            "  Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.12.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow-2.11.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.118\n",
            "  Downloading botocore-1.29.118-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.9/dist-packages (from ftfy->flair->-r textattack_r.txt (line 3)) (0.2.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (6.4.1)\n",
            "Collecting torch!=1.8,>=1.7.0\n",
            "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (2.0.0)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (1.11.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch!=1.8,>=1.7.0->-r textattack_r.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown==4.4.0->flair->-r textattack_r.txt (line 3)) (2.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow->-r textattack_r.txt (line 26)) (3.2.2)\n",
            "Building wheels for collected packages: pinyin, gdown, mpld3, word2number, pycld2, docopt, sqlitedict, langdetect, pptree\n",
            "  Building wheel for pinyin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinyin: filename=pinyin-0.4.0-py3-none-any.whl size=3630492 sha256=e0b3a8963cdadbcb56fd591ddd2dab673c9b2dd355b9a766955dc5df71befd87\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/4d/03/beb69f9530864b62f295333257151b845f5f871b9a32665b9e\n",
            "  Building wheel for gdown (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14776 sha256=7f4ebee2f9a76cb6abd64c9fb5a6bc6f200b58d04da696a1f3c0fe1e5472838a\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/37/b6/b2a79c75e898c0b8e46ff255102602d7159a10d9af0d80641a\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=83b1f5c31ad341a6cf6bec5370bb2a96e3e91e898a173842dc464fa7f86c1c43\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/f4/e6/e40ff9021f6b3854af70fa8ea004f5ab95672817462df08fed\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=e23e68173b83ed089f43ac98798eb6c222d20309c22dd6992b9b0d111ca9f245\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/4a/5b/d2f2df5c344ddbecb8bea759872c207ea91d93f57fb54e816e\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp39-cp39-linux_x86_64.whl size=9915751 sha256=c7e8a2d301621180b6ef816cabd440394cc7860db0a8bf8804c6943d861e093b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/98/60/230df7a9368a02bf62e0e2719a31615b2aa82238dea526b637\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13721 sha256=6673249a56786304b060bced71f92611d796e9fa2bb3c704087e43df9dbb09e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/4a/46/1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=bed4d4fff103506b54aa1ff5392f581407adca6fbbe882eb37eb15f58e574717\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/48/c4/942f7a1d556fddd2348cb9ac262f251873dfd8a39afec5678e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993243 sha256=36fcaf7e3f03d0bf990fe702c6a1a1cdff11cecb27c353e3191915e7d85d11f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=4f035cab8be11eecc6cbe381960010c39a52896a0991e65d4bdc024b4011dce5\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/0e/51/514e690004ea9713bc3fdb678d5e2768fcc597d0c3b6a3abd2\n",
            "Successfully built pinyin gdown mpld3 word2number pycld2 docopt sqlitedict langdetect pptree\n",
            "Installing collected packages: word2number, tokenizers, sqlitedict, sentencepiece, pycld2, pptree, pinyin, mpld3, lru-dict, janome, docopt, xxhash, terminaltables, tensorflow-estimator, tensorboard-data-server, segtok, protobuf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, num2words, multidict, lemminflect, langdetect, keras, jmespath, ftfy, frozenlist, dill, deprecated, conllu, click, async-timeout, anytree, yarl, wikipedia-api, responses, OpenHowNet, nvidia-cusolver-cu11, nvidia-cudnn-cu11, multiprocess, language_tool_python, huggingface-hub, botocore, aiosignal, transformers, s3transfer, google-auth-oauthlib, gdown, bpemb, aiohttp, tensorboard, boto3, tensorflow, datasets, torch, transformer-smaller-training-vocab, pytorch-revgrad, flair, bert-score\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.0\n",
            "    Uninstalling tensorboard-data-server-0.7.0:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.3\n",
            "    Uninstalling click-8.1.3:\n",
            "      Successfully uninstalled click-8.1.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.2\n",
            "    Uninstalling tensorboard-2.12.2:\n",
            "      Successfully uninstalled tensorboard-2.12.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0\n",
            "    Uninstalling torch-1.12.0:\n",
            "      Successfully uninstalled torch-1.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0 requires torch==1.12.0, but you have torch 2.0.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed OpenHowNet-2.0 aiohttp-3.8.4 aiosignal-1.3.1 anytree-2.8.0 async-timeout-4.0.2 bert-score-0.3.13 boto3-1.26.118 botocore-1.29.118 bpemb-0.3.4 click-8.0.4 conllu-4.5.2 datasets-2.4.0 deprecated-1.2.13 dill-0.3.5.1 docopt-0.6.2 flair-0.12.2 frozenlist-1.3.3 ftfy-6.1.1 gdown-4.4.0 google-auth-oauthlib-0.4.6 huggingface-hub-0.13.4 janome-0.4.2 jmespath-1.0.1 keras-2.11.0 langdetect-1.0.9 language_tool_python-2.7.1 lemminflect-0.2.3 lru-dict-1.1.8 mpld3-0.3 multidict-6.0.4 multiprocess-0.70.13 num2words-0.5.12 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pinyin-0.4.0 pptree-3.1 protobuf-3.19.6 pycld2-0.41 pytorch-revgrad-0.2.0 responses-0.18.0 s3transfer-0.6.0 segtok-1.5.11 sentencepiece-0.1.98 sqlitedict-2.1.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorflow-2.11.1 tensorflow-estimator-2.11.0 terminaltables-3.1.10 tokenizers-0.13.3 torch-2.0.0 transformer-smaller-training-vocab-0.2.3 transformers-4.28.1 wikipedia-api-0.5.8 word2number-1.1 xxhash-3.2.0 yarl-1.9.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/loveberryc/SpikeNet.git\n",
        "%cd SpikeNet\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r textattack_r.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYlsw72cCr1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM9Z9HY6dwVr",
        "outputId": "a11decf1-c808-410e-c11b-d9586b5a59ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.21.6)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.18 requires pytz>=2022.5, but you have pytz 2022.1 which is incompatible.\n",
            "torchvision 0.13.0 requires torch==1.12.0, but you have torch 2.0.0 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTz9XSaMRWC2",
        "outputId": "41d4d8da-188a-418f-87a1-d1657e42d458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-22 09:23:34--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-04-22 09:23:35--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2023-04-22 09:26:14 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUWh3UtLSSTS",
        "outputId": "6712c505-b73e-42d7-a0ae-5ae11a1ace22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!cp glove.6B.300d.txt data/"
      ],
      "metadata": {
        "id": "kRUuKQkES_F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#删除数据第一行"
      ],
      "metadata": {
        "id": "Q97P_x53eSSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data_preprocess\n",
        "!python tensor_encoder.py\n",
        "# !python chinese_tensor_encoder.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvR7_esoYSp_",
        "outputId": "3c27b63a-9030-4622-f12a-0b989a3a6b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'data_preprocess'\n",
            "/content/SpikeNet/data_preprocess\n",
            "100% 67349/67349 [05:08<00:00, 218.46it/s]\n",
            "100% 872/872 [00:09<00:00, 94.85it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/SpikeNet/data/sst2/dev_u_3v_sst2_glove300d_sent_len25.tensor_dataset /content/SpikeNet/data/sst2/test_u_3v_sst2_glove300d_sent_len25.tensor_dataset"
      ],
      "metadata": {
        "id": "-VGrsl-cfHvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SpikeNet\n",
        "!python main.py \\\n",
        "--mode train \\\n",
        "--model_mode ann \\\n",
        "--model_type textcnn \\\n",
        "--workspace '/content/SpikeNet' \\\n",
        "--data_dir '/content/SpikeNet/data/sst2'\\\n",
        "--vocab_path '/content/SpikeNet/snn/data/glove.6B.300d.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_i2jzpdaY3F",
        "outputId": "38df5dfb-4707-42dc-ac0d-741acb754f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SpikeNet\n",
            "2023-04-22 10:30:10.816829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 10:30:10.817267: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 10:30:10.817300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Program args: SNNArgs(mode='train', model_mode='ann', model_type='textcnn', dataset_name='sst2', pretrain_embedding_name='glove', label_num=2, seed=42, use_seed='False', epochs=50, batch_size=32, sentence_length=25, hidden_dim=300, num_steps=50, loss='ce_rate', learning_rate=0.0001, weight_decay=0.0, dropout_p=0.5, optimizer_name='Adamw', encode='rate', ensemble='False', ensemble_class=2, max_len=25, attack_method='textfooler', attack_model_path='saved_models/best.pth', attack_times=1, attack_numbers=1000, attack_text_path='data/sst2/test.txt', neighbour_vocab_size=15, modify_ratio=0.3, sentence_similarity=0.8, data_path='data/sst2/train_u_3v_sst2_glove300d_sent_len25.tensor_dataset', test_data_path='data/sst2/test_u_3v_sst2_glove300d_sent_len25.tensor_dataset', dev_data_path='data/sst2/dev_u_3v_sst2_glove300d_sent_len25.tensor_dataset', workspace='/content/SpikeNet', data_dir='/content/SpikeNet/data/sst2', logging_dir='/content/SpikeNet/logs/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2', saving_dir='/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2', vocab_path='/content/SpikeNet/data/glove.6B.300d.txt', attack_logging_dir='/home/XXX/snn/logs_attack', random_tensor='False', surrogate='fast_sigmoid', beta=1.0, filters=[3, 4, 5], filter_num=100, positive_init_rate=0.55, threshold=1.0, dead_neuron_checker='False', conversion_model_path='saved_models/XXX.pth', conversion_mode='normalize', conversion_normalize_type='model_base', power_model_path='..', word2id_path='data/sst2/train_sst2.word2id', args_for_logging=['model_mode', 'mode', 'model_type', 'dataset_name', 'sentence_length', 'dropout_p', 'weight_decay', 'batch_size', 'learning_rate', 'label_num'], device=device(type='cuda'), logging_path='/content/SpikeNet/logs/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:30:24.log')\n",
            "Build dataset...\n",
            "Build dataset...\n",
            "Build dataloader...\n",
            "Build dataloader...\n",
            "Build model...\n",
            "ANN_TextCNN(\n",
            "  (convs_1): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1), bias=False)\n",
            "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1), bias=False)\n",
            "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1), bias=False)\n",
            "  )\n",
            "  (middle_relu): ModuleList(\n",
            "    (0-2): 3 x ReLU()\n",
            "  )\n",
            "  (avgpool_1): ModuleList(\n",
            "    (0): AvgPool2d(kernel_size=(23, 1), stride=(23, 1), padding=0)\n",
            "    (1): AvgPool2d(kernel_size=(22, 1), stride=(22, 1), padding=0)\n",
            "    (2): AvgPool2d(kernel_size=(21, 1), stride=(21, 1), padding=0)\n",
            "  )\n",
            "  (relu_2): ReLU()\n",
            "  (drop): Dropout(p=0.5, inplace=False)\n",
            "  (fc_1): Linear(in_features=300, out_features=2, bias=False)\n",
            ")\n",
            "Build Optimizer...\n",
            "  0% 0/50 [00:00<?, ?it/s]Epoch 0 Acc: 0.5493119266055045\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:31:06.log--epoch0.pth\n",
            "  2% 1/50 [00:15<12:16, 15.02s/it]Epoch 1 Acc: 0.6697247706422018\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:31:15.log--epoch1.pth\n",
            "  4% 2/50 [00:24<09:21, 11.70s/it]Epoch 2 Acc: 0.7373853211009175\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:31:23.log--epoch2.pth\n",
            "  6% 3/50 [00:32<07:50, 10.00s/it]Epoch 3 Acc: 0.7247706422018348\n",
            "  8% 4/50 [00:39<06:44,  8.80s/it]Epoch 4 Acc: 0.7488532110091743\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:31:39.log--epoch4.pth\n",
            " 10% 5/50 [00:48<06:46,  9.03s/it]Epoch 5 Acc: 0.7224770642201835\n",
            " 12% 6/50 [00:55<06:08,  8.38s/it]Epoch 6 Acc: 0.7603211009174312\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:31:54.log--epoch6.pth\n",
            " 14% 7/50 [01:03<05:46,  8.05s/it]Epoch 7 Acc: 0.7522935779816514\n",
            " 16% 8/50 [01:13<06:02,  8.63s/it]Epoch 8 Acc: 0.7511467889908257\n",
            " 18% 9/50 [01:19<05:28,  8.02s/it]Epoch 9 Acc: 0.7178899082568807\n",
            " 20% 10/50 [01:27<05:21,  8.04s/it]Epoch 10 Acc: 0.7591743119266054\n",
            " 22% 11/50 [01:36<05:26,  8.36s/it]Epoch 11 Acc: 0.7029816513761468\n",
            " 24% 12/50 [01:43<04:59,  7.87s/it]Epoch 12 Acc: 0.7786697247706422\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:32:43.log--epoch12.pth\n",
            " 26% 13/50 [01:52<05:02,  8.18s/it]Epoch 13 Acc: 0.768348623853211\n",
            " 28% 14/50 [02:00<04:54,  8.18s/it]Epoch 14 Acc: 0.7775229357798165\n",
            " 30% 15/50 [02:07<04:33,  7.83s/it]Epoch 15 Acc: 0.7694954128440367\n",
            " 32% 16/50 [02:17<04:43,  8.34s/it]Epoch 16 Acc: 0.7855504587155964\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:33:16.log--epoch16.pth\n",
            " 34% 17/50 [02:24<04:28,  8.12s/it]Epoch 17 Acc: 0.7775229357798165\n",
            " 36% 18/50 [02:32<04:11,  7.86s/it]Epoch 18 Acc: 0.768348623853211\n",
            " 38% 19/50 [02:41<04:17,  8.31s/it]Epoch 19 Acc: 0.7545871559633027\n",
            " 40% 20/50 [02:48<03:57,  7.91s/it]Epoch 20 Acc: 0.7775229357798165\n",
            " 42% 21/50 [02:56<03:47,  7.84s/it]Epoch 21 Acc: 0.7763761467889908\n",
            " 44% 22/50 [03:05<03:49,  8.18s/it]Epoch 22 Acc: 0.7775229357798165\n",
            " 46% 23/50 [03:12<03:31,  7.82s/it]Epoch 23 Acc: 0.7809633027522935\n",
            " 48% 24/50 [03:20<03:28,  8.02s/it]Epoch 24 Acc: 0.783256880733945\n",
            " 50% 25/50 [03:28<03:22,  8.10s/it]Epoch 25 Acc: 0.7844036697247706\n",
            " 52% 26/50 [03:35<03:04,  7.68s/it]Epoch 26 Acc: 0.7763761467889908\n",
            " 54% 27/50 [03:44<03:06,  8.12s/it]Epoch 27 Acc: 0.7465596330275229\n",
            " 56% 28/50 [03:52<02:56,  8.04s/it]Epoch 28 Acc: 0.7901376146788991\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:34:50.log--epoch28.pth\n",
            " 58% 29/50 [03:59<02:42,  7.74s/it]Epoch 29 Acc: 0.7706422018348624\n",
            " 60% 30/50 [04:09<02:44,  8.24s/it]Epoch 30 Acc: 0.7591743119266054\n",
            " 62% 31/50 [04:16<02:29,  7.84s/it]Epoch 31 Acc: 0.7878440366972477\n",
            " 64% 32/50 [04:23<02:19,  7.76s/it]Epoch 32 Acc: 0.783256880733945\n",
            " 66% 33/50 [04:32<02:20,  8.25s/it]Epoch 33 Acc: 0.7924311926605505\n",
            "/content/SpikeNet/saved_models/model_modeann-modetrain-model_typetextcnn-dataset_namesst2-sentence_length25-dropout_p0.5-weight_decay0.0-batch_size32-learning_rate0.0001-label_num2/2023-04-22 10:35:30.log--epoch33.pth\n",
            " 68% 34/50 [04:39<02:04,  7.78s/it]Epoch 34 Acc: 0.7878440366972477\n",
            " 70% 35/50 [04:47<01:58,  7.90s/it]Epoch 35 Acc: 0.783256880733945\n",
            " 72% 36/50 [04:56<01:53,  8.10s/it]Epoch 36 Acc: 0.7889908256880734\n",
            " 74% 37/50 [05:03<01:39,  7.69s/it]Epoch 37 Acc: 0.7844036697247706\n",
            " 76% 38/50 [05:11<01:36,  8.01s/it]Epoch 38 Acc: 0.783256880733945\n",
            " 78% 39/50 [05:19<01:27,  7.99s/it]Epoch 39 Acc: 0.7637614678899083\n",
            " 80% 40/50 [05:26<01:16,  7.66s/it]Epoch 40 Acc: 0.7821100917431193\n",
            " 82% 41/50 [05:35<01:13,  8.13s/it]Epoch 41 Acc: 0.7889908256880734\n",
            " 84% 42/50 [05:43<01:03,  7.91s/it]Epoch 42 Acc: 0.7889908256880734\n",
            " 86% 43/50 [05:50<00:54,  7.72s/it]Epoch 43 Acc: 0.7889908256880734\n",
            " 88% 44/50 [06:00<00:49,  8.27s/it]Epoch 44 Acc: 0.7855504587155964\n",
            " 90% 45/50 [06:06<00:39,  7.82s/it]Epoch 45 Acc: 0.7809633027522935\n",
            " 92% 46/50 [06:14<00:31,  7.77s/it]Epoch 46 Acc: 0.783256880733945\n",
            " 94% 47/50 [06:23<00:24,  8.16s/it]Epoch 47 Acc: 0.7844036697247706\n",
            " 96% 48/50 [06:30<00:15,  7.70s/it]Epoch 48 Acc: 0.783256880733945\n",
            " 98% 49/50 [06:38<00:07,  7.92s/it]Epoch 49 Acc: 0.7706422018348624\n",
            "100% 50/50 [06:47<00:00,  8.14s/it]\n",
            "Best Test Acc: 0.7924311926605505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "--mode conversion\\\n",
        "--model_mode snn\\\n",
        "--model_type textcnn\\\n",
        "--conversion_mode tune"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfTbbZOihwvg",
        "outputId": "ca035366-aa46-4f4f-9f6e-5ea3d2896f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-22 10:41:11.747889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 10:41:11.748360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 10:41:11.748394: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Program args: SNNArgs(mode='conversion', model_mode='snn', model_type='textcnn', dataset_name='sst2', pretrain_embedding_name='glove', label_num=2, seed=42, use_seed='False', epochs=50, batch_size=32, sentence_length=25, hidden_dim=300, num_steps=50, loss='ce_rate', learning_rate=0.0001, weight_decay=0.0, dropout_p=0.5, optimizer_name='Adamw', encode='rate', ensemble='False', ensemble_class=2, max_len=25, attack_method='textfooler', attack_model_path='saved_models/best.pth', attack_times=1, attack_numbers=1000, attack_text_path='data/sst2/test.txt', neighbour_vocab_size=15, modify_ratio=0.3, sentence_similarity=0.8, data_path='data/sst2/train_u_3v_sst2_glove300d_sent_len25.tensor_dataset', test_data_path='data/sst2/test_u_3v_sst2_glove300d_sent_len25.tensor_dataset', dev_data_path='data/sst2/dev_u_3v_sst2_glove300d_sent_len25.tensor_dataset', workspace='/home/XXX/snn', data_dir='/home/XXX/snn/data/sst2', logging_dir='/home/XXX/snn/logs/model_modesnn-modeconversion-conversion_modetune-model_typetextcnn-dataset_namesst2-conversion_normalize_typemodel_base-label_num2-positive_init_rate0.55-num_steps50-learning_rate0.0001', saving_dir='/home/XXX/snn/saved_models/model_modesnn-modeconversion-conversion_modetune-model_typetextcnn-dataset_namesst2-conversion_normalize_typemodel_base-label_num2-positive_init_rate0.55-num_steps50-learning_rate0.0001', vocab_path='/home/XXX/snn/data/glove.6B.300d.txt', attack_logging_dir='/home/XXX/snn/logs_attack', random_tensor='False', surrogate='fast_sigmoid', beta=1.0, filters=[3, 4, 5], filter_num=100, positive_init_rate=0.55, threshold=1.0, dead_neuron_checker='False', conversion_model_path='saved_models/XXX.pth', conversion_mode='tune', conversion_normalize_type='model_base', power_model_path='..', word2id_path='data/sst2/train_sst2.word2id', args_for_logging=['model_mode', 'mode', 'conversion_mode', 'model_type', 'dataset_name', 'conversion_normalize_type', 'label_num', 'positive_init_rate', 'num_steps', 'learning_rate'], device=device(type='cuda'), logging_path='/home/XXX/snn/logs/model_modesnn-modeconversion-conversion_modetune-model_typetextcnn-dataset_namesst2-conversion_normalize_typemodel_base-label_num2-positive_init_rate0.55-num_steps50-learning_rate0.0001/2023-04-22 10:41:28.log')\n",
            "Build model...\n",
            "SNN_TextCNN(\n",
            "  (convs_1): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
            "  )\n",
            "  (middle_lifs): ModuleList(\n",
            "    (0-2): 3 x Leaky()\n",
            "  )\n",
            "  (avgpool_1): ModuleList(\n",
            "    (0): AvgPool2d(kernel_size=(23, 1), stride=(23, 1), padding=0)\n",
            "    (1): AvgPool2d(kernel_size=(22, 1), stride=(22, 1), padding=0)\n",
            "    (2): AvgPool2d(kernel_size=(21, 1), stride=(21, 1), padding=0)\n",
            "  )\n",
            "  (lif1): Leaky()\n",
            "  (fc_1): Linear(in_features=300, out_features=2, bias=True)\n",
            "  (lif2): Leaky()\n",
            ")\n",
            "Build dataset...\n",
            "Build dataset...\n",
            "Build dataset...\n",
            "Build rated_dataset...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip sst2.zip /content/SpikeNet/data/sst2/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cQqWmqej0F2",
        "outputId": "678223b7-90f3-454e-87b1-96469dade888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/SpikeNet/data/sst2/dev.tsv (deflated 60%)\n",
            "  adding: content/SpikeNet/data/sst2/dev_u_3v_sst2_glove300d_sent_len25.tensor_dataset (deflated 62%)\n",
            "  adding: content/SpikeNet/data/sst2/original/ (stored 0%)\n",
            "  adding: content/SpikeNet/data/sst2/test.tsv (deflated 59%)\n",
            "  adding: content/SpikeNet/data/sst2/test_u_3v_sst2_glove300d_sent_len25.tensor_dataset (deflated 62%)\n",
            "  adding: content/SpikeNet/data/sst2/train.tsv (deflated 62%)\n",
            "  adding: content/SpikeNet/data/sst2/train_u_3v_sst2_glove300d_sent_len25.tensor_dataset (deflated 80%)\n"
          ]
        }
      ]
    }
  ]
}